# Part of the code for this project was generated by ChatGPT.

#pip install seaborn scikit-learn transformers torch

#Importing modules
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.pipeline import make_pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.dummy import DummyClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import make_pipeline


#SST DATASET 
#train_data = pd.read_csv('Datasæt final/Original_train.csv')
#train_data = pd.read_csv('Datasæt final/sst_paraphrase_05.csv')
#train_data = pd.read_csv('Datasæt final/paraphrase_15_v2.csv')
#train_data = pd.read_csv('Datasæt final/sst_chatgpt.csv')
#train_data = pd.read_csv('Datasæt final/original_plus_chatgpt.csv')
#train_data = pd.read_csv('Datasæt final/sst_paraphrase_original_and_05.csv')

#COLA DATASET
#train_data = pd.read_csv('Datasæt Cola/cola_train.csv')
#train_data = pd.read_csv('Datasæt Cola/cola_paraphrase05.csv')
#train_data = pd.read_csv('Datasæt Cola/cola_paraphrase_15.csv')
#train_data = pd.read_csv('Datasæt Cola/cola_chatgpt.csv')
#train_data = pd.read_csv('Datasæt Cola/cola_original_para05.csv')
#train_data = pd.read_csv('Datasæt Cola/cola_original_chatgpt.csv')

# SST DEV DATASET
#dev_data = pd.read_csv('Datasæt final/dev.csv')

# COLA DEV DATASET
#dev_data = pd.read_csv('Datasæt Cola/dev.csv')

#SST TEST DATASET
#test_data = pd.read_csv('Datasæt final/Original_test.csv')

#Stanford IMDB TEST DATASET
#test_data = pd.read_csv('Datasæt final/IMDB_dataset.csv')

#COLA TEST DATASET
#test_data = pd.read_csv('Datasæt Cola/cola_test.csv')

#Picking Datasets
train_data = pd.read_csv('Datasæt Cola/cola_original_para05.csv')
dev_data = pd.read_csv('Datasæt Cola/dev.csv')
test_data = pd.read_csv('Datasæt Cola/cola_test.csv')

# Defining X and Y values for train, dev and test
X_train = train_data["sentence"]
y_train = train_data["label"]

X_dev = dev_data["sentence"]
y_dev = dev_data["label"]

X_test = test_data["sentence"]
y_test = test_data["label"]

X_train_part, X_val, y_train_part, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)  

#____________________Dummy Classifier____________________

pipe_dummy = make_pipeline(TfidfVectorizer(), DummyClassifier())

param_log_dummy = {
    'dummyclassifier__strategy': ['most_frequent', 'uniform']
}

grid_dummy = GridSearchCV(pipe_dummy, param_log_dummy, scoring='accuracy', cv=3, n_jobs=-1)
grid_dummy.fit(X_train_part, y_train_part)  # Now fitting on the training part

pipe_dummy.set_params(**grid_dummy.best_params_)
optimal_params = grid_dummy.best_params_
print("Optimal Parameters:", optimal_params)
pipe_dummy.fit(X_train, y_train)

y_test_pred = pipe_dummy.predict(X_test)
test_report = classification_report(y_test, y_test_pred)
print("Test Set Evaluation:\n", test_report)

#____________________LOGISTIC REGRESSION____________________

pipe_log = make_pipeline(TfidfVectorizer(), LogisticRegression(max_iter=2000))

#GRIDSEARCH
# param_grid_log = {
#    'tfidfvectorizer__max_df': [0.5, 0.75, 0.9, 0.95],
#    'tfidfvectorizer__ngram_range':  [(1, 2), (2, 3), (3, 4)],
#    'tfidfvectorizer__min_df': [1, 2, 3],
#    'tfidfvectorizer__sublinear_tf': [True, False],
#    'logisticregression__C': [0.01, 0.1, 1, 10, 100],
#    'logisticregression__penalty': ['l1', 'l2'],
#    'logisticregression__solver': ['liblinear']
#}

# SST TRAIN OPTIMAL PARAMETERS
param_grid_log = {
    'tfidfvectorizer__max_df': [0.5],
    'tfidfvectorizer__ngram_range':  [(2, 3)],
    'tfidfvectorizer__min_df': [1],
    'tfidfvectorizer__sublinear_tf': [True],
    'logisticregression__C': [1],
    'logisticregression__penalty': ['l2'],
    'logisticregression__solver': ['liblinear']
}


# COLA TRAIN OPTIMAL PARAMETERS
param_grid_log = {
    'tfidfvectorizer__max_df': [0.5],
    'tfidfvectorizer__ngram_range':  [(2, 3)],
    'tfidfvectorizer__min_df': [1],
    'tfidfvectorizer__sublinear_tf': [True],
    'logisticregression__C': [1],
    'logisticregression__penalty': ['l2'],
    'logisticregression__solver': ['liblinear']
}

grid_log = GridSearchCV(pipe_log, param_grid_log, scoring='accuracy', cv=3, n_jobs=-1)
grid_log.fit(X_train_part, y_train_part)  

# Development dataset evaluation
y_dev_pred = grid_log.predict(X_dev)
dev_report = classification_report(y_dev, y_dev_pred)
print("Development Set Evaluation:\n", dev_report)

# Best parameters
pipe_log.set_params(**grid_log.best_params_)
optimal_params = grid_log.best_params_
print("Optimal Parameters:", optimal_params)
pipe_log.fit(X_train, y_train)

# Test dataset evaluation
y_test_pred = pipe_log.predict(X_test)
test_report = classification_report(y_test, y_test_pred)
print("Test Set Evaluation:\n", test_report)